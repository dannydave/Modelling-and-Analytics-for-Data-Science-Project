#
# Function to work out the sample mean and trimmed mean
# of data passed through in x
# trim: the fraction (0 to 0.5) of observations to be trimmed from each end of x
# before the mean is computed
#
out_m <- mean(x) # Sample mean
out_m_trimmed <- mean(x, trim = trim) # Trimmed mean
#
# Return these values in a list
#
return(list(M = out_m, M_TRIMMED = out_m_trimmed))
# We can specify names for the returned objects
}
#
# ------------------------------------------------------------------
#
# Examples, applied to the speed of the group
#
questionnaire_data_2 <- questionnaire_data %>%
mutate(Speed = Distance / Travel_time, Speed_mph = 60 * Speed)
#
# Look at the values of speed in miles per hour
#
questionnaire_data_2$Speed_mph
#
trimmed_mean(questionnaire_data_2$Speed_mph) # Uses the default value of trim (0.1)
trimmed_mean(questionnaire_data_2$Speed_mph, trim = 0.2) # Sets trim = 0.2
#
# We can extract the individual elements of the results using $
#
results <- trimmed_mean(questionnaire_data_2$Speed_mph)
results$M # Extract M, the sample mean
results$M_TRIMMED # Sample trimmed mean
results_2 <- trimmed_mean(questionnaire_data_2$Speed_mph, trim = 0.2)
results_2$M
results_2$M_TRIMMED
#
# Compare these sample trimmed means
#
c(results$M_TRIMMED, results_2$M_TRIMMED)
#
# They are different, but the sample means are the same
#
c(results$M, results_2$M)
#
#
# ------------------------------------------------------------------
#
# It's worth noting that there are various ways of referring to the arguments of a function
#
# Above we used
#
trimmed_mean(questionnaire_data_2$Speed_mph, trim = 0.2)
#
# We can name each argument
#
args(trimmed_mean) # Check what the arguments are
#
trimmed_mean(x = questionnaire_data_2$Speed_mph, trim = 0.2) # Named arguments
#
# Naming the arguments allows us not to worry about the order in which they are specified
#
trimmed_mean(trim = 0.2, x = questionnaire_data_2$Speed_mph) # Works fine!
#
#
# ------------------------------------------------------------------
#
# ***** A way of documenting a function that will be of use later *****
#
# Documenting our functions is very important.
# It helps others to understand what the function does.
# It's important to note that "others" in this sentence can refer to "future you"!
#
# Here we present a way of documenting our function that will be useful later:
#' Statistical Summaries of a Numeric Data Set
#'
#' This function provides statistical summaries of
#' a numeric data set.
#'
#' @param x A numeric vector containing the data.
#' @param trim The fraction (0 to 0.5) of observations to be trimmed from each end of x before the mean is computed. Default is 0.1.
#'
#' @return A named vector of numerical summaries:
#' \describe{
#' \item{M}{The mean of the data.}
#' \item{M_TRIMMED}{The trimmed mean of the data.}
#' }
trimmed_mean <- function(x, trim = 0.1){
#
out_m <- mean(x) # Sample mean
out_m_trimmed <- mean(x, trim = trim) # Trimmed mean
#
# Return these values in a list
#
return(list(M = out_m, M_TRIMMED = out_m_trimmed))
}
# The solution to the 4th task----------------------
x <- c(2, 6, NA, 5, 2, 1, NA, 6, 6, 7, NA, 4, 0)
statistics_NA <- function(x, na.rm = T){
min <- min(x, na.rm)
mean <- mean(x, na.rm)
sd <- sd(x, na.rm)
max <- max(x, na.rm)
number_missing <- sum(is.na(x))
df <- data.frame(min, mean, sd, max, number_missing)
returnValue(df)
}
## $min
statistics_NA(x)$min
## $mean
statistics_NA(x)$mean
## $sd
statistics_NA(x)$sd
## $max
statistics_NA(x)$max
## $number_missing
statistics_NA(x)$number_missing
## $min
statistics_NA(x, na.rm = F)$min
## $mean
statistics_NA(x, na.rm = F)$mean
## $sd
statistics_NA(x, na.rm = F)$sd
## $max
statistics_NA(x, na.rm = F)$max
## $number_missing
statistics_NA(x, na.rm = F)$number_missing
# The solution to the 4th task----------------------
statistics_NA <- function(x, na.rm = T){
x <- c(2, 6, NA, 5, 2, 1, NA, 6, 6, 7, NA, 4, 0)
min <- min(x)
mean <- mean(x)
sd <- sd(x, na.rm)
max <- max(x, na.rm)
number_missing <- sum(is.na(x))
df <- data.frame(min, mean, sd, max, number_missing)
returnValue(df)
}
## $min
statistics_NA(x)$min
## $mean
statistics_NA(x)$mean
## $sd
statistics_NA(x)$sd
## $max
statistics_NA(x)$max
## $number_missing
statistics_NA(x)$number_missing
## $min
statistics_NA(x, na.rm = F)$min
## $mean
statistics_NA(x, na.rm = F)$mean
## $sd
statistics_NA(x, na.rm = F)$sd
## $max
statistics_NA(x, na.rm = F)$max
## $number_missing
statistics_NA(x, na.rm = F)$number_missing
# The solution to the 4th task----------------------
statistics_NA <- function(x, na.rm = T){
x <- c(2, 6, NA, 5, 2, 1, NA, 6, 6, 7, NA, 4, 0)
min <- min(x, na.rm)
mean <- mean(x, na.rm)
sd <- sd(x, na.rm)
max <- max(x, na.rm)
number_missing <- sum(is.na(x))
df <- data.frame(min, mean, sd, max, number_missing)
returnValue(df)
}
## $min
statistics_NA(x)$min
## $mean
statistics_NA(x)$mean
## $sd
statistics_NA(x)$sd
## $max
statistics_NA(x)$max
## $number_missing
statistics_NA(x)$number_missing
## $min
statistics_NA(x, na.rm = F)$min
## $mean
statistics_NA(x, na.rm = F)$mean
## $sd
statistics_NA(x, na.rm = F)$sd
## $max
statistics_NA(x, na.rm = F)$max
## $number_missing
statistics_NA(x, na.rm = F)$number_missing
# The solution to the 4th task----------------------
statistics_NA <- function(x, na.rm = T){
x <- c(2, 6, NA, 5, 2, 1, NA, 6, 6, 7, NA, 4, 0)
min <- min(x)
mean <- mean(x)
sd <- sd(x)
max <- max(x)
number_missing <- sum(is.na(x))
df <- data.frame(min, mean, sd, max, number_missing)
returnValue(df)
}
## $min
statistics_NA(x)$min
## $mean
statistics_NA(x)$mean
## $sd
statistics_NA(x)$sd
## $max
statistics_NA(x)$max
## $number_missing
statistics_NA(x)$number_missing
## $min
statistics_NA(x, na.rm = F)$min
## $mean
statistics_NA(x, na.rm = F)$mean
## $sd
statistics_NA(x, na.rm = F)$sd
## $max
statistics_NA(x, na.rm = F)$max
## $number_missing
statistics_NA(x, na.rm = F)$number_missing
install.packages("latexpdf")
library(latexpdf)
install.packages("tinytex")
install.packages("pandoc")
Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
install.packages('tinytex')
library(tinytex)
install.packages("tinytex")
tinytex::install_tinytex()
library(formatR)
library(formatR)
install.packages(c('dplyr', 'devtools', 'ggplot2', 'quantmod'))
install.packages(c('XBRL', 'finreportr', 'cowplot', 'Rmisc', 'gridExtra'))
library(devtools)
install_github("bergant/finstr")
# if you do not see any error messages then you are all set.
install.packages(c('dplyr', 'devtools', 'ggplot2', 'quantmod'))
install.packages(c("dplyr", "devtools", "ggplot2", "quantmod"))
install.packages(c('XBRL', 'finreportr', 'cowplot', 'Rmisc', 'gridExtra'))
library(devtools)
install_github("bergant/finstr")
library(plyr)
library(dplyr)
library(XBRL)
library(finreportr)
library(devtools)
library(ggplot2)
library(cowplot)
library(quantmod)
library(Rmisc)
library(gridExtra)
library(finstr)
# if you do not see any error messages then you are all set.
# if you do not see any error messages then you are all set.
# if you see warning messages don't worry, that's fine anyway.
# if you do not see any error messages then you are all set.
# if you see warning messages don't worry, that's fine anyway.
# if you do not see any error messages then you are all set.
# if you see warning messages don't worry, that's fine anyway.
install.packages(c('dplyr', 'devtools', 'ggplot2', 'quantmod'))
install.packages(c('XBRL', 'finreportr', 'cowplot', 'Rmisc', 'gridExtra'))
library(devtools)
install_github("bergant/finstr")
library(plyr)
library(dplyr)
library(XBRL)
library(finreportr)
library(devtools)
library(ggplot2)
library(cowplot)
library(quantmod)
library(Rmisc)
library(gridExtra)
library(finstr)
# Exercise 1: SIMPLE LINEAR REGRESSION
# install.packages("alr4", repos = "http://www.stats.bris.ac.uk/R/") # Needed on your own machine
library(alr4)
head(Forbes)
df <- data.frame(Forbes)
df
?alr4
?alr4
#----------------------------------------------
library(ggplot2) # For powerful graphics
#----------------------------------------------
library(ggplot2) # For powerful graphics
ggplot(df, aes(x = pres, y = bp)) +
geom_point() +
labs(x = "Pressure (inches of mercury)",
y = "Temperature (degree Farenheit)",
title = "Data int the Forbes",
subtitle = "Random sample of size 6")
library(dplyr)
#
summary_forbes <- Forbes %>%
summarise(mean_pres = mean(pres),
median_pres = median(pres),
var_pres = var(pres),
sd_pres = sd(pres),
IQR_pres = IQR(pres),
mean_bp = mean(bp),
median_bp = median(bp),
var_bp = var(bp),
sd_bp = sd(bp),
IQR_bp = IQR(bp))
summary_forbes
?summarise
summary_forbes
# Using with -------------------------------------------
mean_pres <- with(Forbes, mean(pres))
median_pres <- with(Forbes, median(pres))
var_pres <- with(Forbes, var(pres))
sd_pres <- with(Forbes, sd(pres))
IQR_pres <- with(Forbes, IQR(pres))
mean_bp <- with(Forbes, mean(bp))
median_bp <- with(Forbes, median(bp))
var_bp <- with(Forbes, var(bp))
sd_bp <- with(Forbes, sd(bp))
IQR_bp <- with(Forbes, IQR(bp))
mean_pres; median_pres; var_pres; sd_pres; IQR_pres
mean_bp; median_bp; var_bp; sd_bp; IQR_bp
m <- lm(bp ~ pres, data = Forbes)
coef(m)
# Use the geom_smooth geometry from the ggplot2 package to show in blue the fitted line on the plot that you created above-----------------------------------
ggplot(Forbes,
aes(x = pres, y = bp)) +
geom_point() +
geom_smooth(method = "lm", se = FALSE, colour = "blue") +
labs(x = "Pressure (inches of mercury)",
y = "Temperature (degrees Farenheight)")
# Use the function add_predictions from the modelr package to compute the fitted values and to include them with the original data. Add these fitted values to your plot in green.------------------
library(modelr)
# Use the geom_smooth geometry from the ggplot2 package to show in blue the fitted line on the plot that you created above-----------------------------------
ggplot(Forbes,
aes(x = pres, y = bp)) +
geom_point() +
geom_smooth(method = "lm", se = FALSE, colour = "blue") +
labs(x = "Pressure (inches of mercury)",
y = "Temperature (degrees Farenheight)")
# Use the function add_predictions from the modelr package to compute the fitted values and to include them with the original data. Add these fitted values to your plot in green.------------------
library(modelr)
#
forbes_with_fitted_values <- Forbes %>%
# Add the fitted values or predictions from m
add_predictions(m)
#
ggplot(forbes_with_fitted_values,
aes(x = pres, y = bp)) +
geom_point() +
geom_smooth(method = "lm", se = FALSE, colour = "blue") +
geom_point(aes(y = pred), col = "green", pch = 17, size = 3) +
labs(x = "Pressure (inches of mercury)",
y = "Temperature (degrees Farenheight)")
# Is there an underlying relationship between temperature and pressure? Justify your conclusion.-------------------
summary(m)
# Here is the relevant p-value:
pvalue <- signif(summary(m)$coefficients[2,4], 3) # Save the p-value to three significant figures
pvalue
# Add the confidence and prediction intervals lines to your graph-----------------------
forbes_conf <- data.frame(Forbes, predict(m, interval = "confidence"))
forbes_pred <- data.frame(Forbes, predict(m, interval = "prediction"))
#
# Add prediction intervals to the plot
#
ggplot(forbes_with_fitted_values,
aes(x = pres, y = bp)) +
geom_point() +
geom_smooth(method = "lm", se = TRUE, colour = "blue") +
geom_line(aes(y = lwr), colour = "blue", data = forbes_conf) +
geom_line(aes(y = upr), colour = "blue", data = forbes_conf) +
geom_line(aes(y = lwr), colour = "red", data = forbes_pred) +
geom_line(aes(y = upr), colour = "red", data = forbes_pred) +
labs(x = "Pressure (inches of mercury)",
y = "Temperature (degrees Farenheight)")
load("C:/Users/User/Downloads/jc.RData")
load("C:/Users/User/Downloads/Bassey/jc.RData")
install.packages("posterdown")
library(ISLR)
data(OJ)
?OJ
OJ
dim(OJ)
set.seed(123) # For reproducibility
train_index <- sample(1:nrow(OJ), 800)
train_set <- OJ[train_index, ]
test_set <- OJ[-train_index, ]
library(tree)
install.packages("tree")
library(tree)
# Fitting the tree
tree_model <- tree(Purchase ~ ., data = train_set)
summary(tree_model)
plot(tree_model)
text(tree_model, pretty = 0)
# Predicting the test data and producing a confusion matrix
test_pred <- predict(tree_model, test_set, type = "class")
confusion_matrix <- table(test_set$Purchase, test_pred)
confusion_matrix
test_error_rate <- sum(diag(confusion_matrix))/sum(confusion_matrix)
# Determining the optimal tree size
cv_tree <- cv.tree(tree_model, FUN = prune.tree)
cv_tree
# Plotting the tree size versus cross-validated classification error rate
plot(cv_tree$size, cv_tree$dev, type = "b")
# Pruning the tree
prune_tree <- prune.tree(tree_model, best = which.min(cv_tree$dev))
if(length(prune_tree$size) == 1){
prune_tree <- prune.tree(tree_model, best = 5)
}
library(randomForest)
install.packages("randomForest")
library(randomForest)
rf_model <- randomForest (Purchase ~ ., data = train_set, mtry = 3)
varImport(rf_model)
install.packages("varImp")
varImport(rf_model)
rf_model
library(randomForest)
set.seed(123)
rf_model <- randomForest (Purchase ~ ., data = train_set, mtry = 3)
varImport(rf_model)
varImpPlot(rf_model)
# For unpruned tree
unpruned_train_pred <- predict(tree_model, train_set, type = "class")
unpruned_train_confusion <- table(train_set$Purchase, unpruned_train_pred)
unpruned_training_error_rate <- 1 - sum(diag(unpruned_train_confusion)) / sum(unpruned_train_confusion)
# For pruned tree
pruned_train_pred <- predict(prune_tree, train_set, type = "class")
pruned_train_confusion <- table(train_set$Purchase, pruned_train_pred)
pruned_training_error_rate <- 1 - sum(diag(pruned_train_confusion)) / sum(pruned_train_confusion)
unpruned_training_error_rate
pruned_training_error_rate
# For unpruned tree
# Assuming test_pred contains the predictions for the test set using the unpruned tree
unpruned_test_confusion <- table(test_set$Purchase, test_pred)
unpruned_test_error_rate <- 1 - sum(diag(unpruned_test_confusion)) / sum(unpruned_test_confusion)
unpruned_test_error_rate
# For pruned tree
pruned_test_pred <- predict(prune_tree, test_set, type = "class")
pruned_test_confusion <- table(test_set$Purchase, pruned_test_pred)
pruned_test_error_rate <- 1 - sum(diag(pruned_test_confusion)) / sum(pruned_test_confusion)
pruned_test_error_rate
prune_tree
library(ISLR)
library(tree)
data(OJ)
dim(OJ)
attach(OJ)
# Setting a seed ensures that the random sample is reproducible. 800 observations are randomly sampled for the training set, and the remaining observations constitute the test set.
set.seed(123) # For reproducibility
train_index <- sample(1:nrow(OJ), 800)
train_set <- OJ[train_index, ]
test_set <- OJ[-train_index, ]
# Fitting the tree
# The tree() function fits a tree to the training data with Purchase as the response and all other variables as predictors. The summary() function will provide the tree's summary statistics, including the training error rate and the number of terminal nodes.
tree_model <- tree(Purchase ~ ., data = train_set)
summary(tree_model)
# Displaying the tree graphically
plot(tree_model)
text(tree_model, pretty = 0)
# Predicting the test data and producing a confusion matrix
# The predict() function is used to classify the test set, and table() function creates a confusion matrix of the true classes versus the predicted classes. The test error rate is then calculated as the sum of the diagonal (correct predictions) divided by the total number of observations in the test set.
test_pred <- predict(tree_model, test_set, type = "class")
confusion_matrix <- table(test_set$Purchase, test_pred)
confusion_matrix
test_error_rate <- sum(diag(confusion_matrix))/sum(confusion_matrix)
# Determining the optimal tree size
# The cv.tree() function performs cross-validation on the tree model. The output includes the size of the tree and corresponding error rates, which help in determining the optimal size.
cv_tree <- cv.tree(tree_model, FUN = prune.tree)
cv_tree
# Plotting the tree size versus cross-validated classification error rate
# The point at which the error rate is the lowest indicates the optimal size of the tree
plot(cv_tree$size, cv_tree$dev, type = "b")
# Pruning the tree
# The prune.tree() function is used to prune the tree to the optimal size determined by cross-validation. If cross-validation suggests not pruning the tree, then a pruned tree with five terminal nodes is created as per the instructions.
prune_tree <- prune.tree(tree_model, best = which.min(cv_tree$dev))
if(length(prune_tree$size) == 1){
prune_tree <- prune.tree(tree_model, best = 5)
}
prune_tree
plot(prune_tree)
text(prune_tree, pretty = 0)
# For unpruned tree
unpruned_train_pred <- predict(tree_model, train_set, type = "class")
unpruned_train_confusion <- table(train_set$Purchase, unpruned_train_pred)
unpruned_training_error_rate <- 1 - sum(diag(unpruned_train_confusion)) / sum(unpruned_train_confusion)
unpruned_training_error_rate
# For pruned tree
pruned_train_pred <- predict(prune_tree, train_set, type = "class")
pruned_train_confusion <- table(train_set$Purchase, pruned_train_pred)
pruned_training_error_rate <- 1 - sum(diag(pruned_train_confusion)) / sum(pruned_train_confusion)
pruned_training_error_rate
# For unpruned tree
# Assuming test_pred contains the predictions for the test set using the unpruned tree
unpruned_test_confusion <- table(test_set$Purchase, test_pred)
unpruned_test_error_rate <- 1 - sum(diag(unpruned_test_confusion)) / sum(unpruned_test_confusion)
unpruned_test_error_rate
# For pruned tree
pruned_test_pred <- predict(prune_tree, test_set, type = "class")
pruned_test_confusion <- table(test_set$Purchase, pruned_test_pred)
pruned_test_error_rate <- 1 - sum(diag(pruned_test_confusion)) / sum(pruned_test_confusion)
pruned_test_error_rate
# Fitting a random forest and interpreting variable importance
library(randomForest)
set.seed(123)
rf_model <- randomForest (Purchase ~ ., data = train_set, mtry = 3)
varImpPlot(rf_model)
detach(OJ)
setwd("C:/Users/User/OneDrive - University of Plymouth/MATH 501/Statistical Modelling/MATH 501 COURSEWORK")
